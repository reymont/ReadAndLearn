
# 什么是无监督学习

[什么是无监督学习？ - 知乎 ](https://www.zhihu.com/question/23194489)

是否有监督（supervised），就看输入数据是否有标签（label）。输入数据有标签，则为有监督学习，没标签则为无监督学习。

机器学习利用某些训练数据，使机器能够利用它们分析未知数据。分类（classification）是最常见的一种机器学习算法。分类的训练数据有两种：特征（feature）和标签（label）。所谓的学习，其本质就是找到特征和标签间的关系（mapping）。这样当有特征而无标签的未知数据输入时，我们就可以通过已有的关系得到未知数据标签。

在上述的分类过程中，如果所有训练数据都有标签，则为有监督学习（supervised learning）。如果数据没有标签，显然就是无监督学习（unsupervised learning）了，也即聚类（clustering）。

# 监督学习和无监督学习

[AI Horizon: Introduction to Machine Learning ](http://www.aihorizon.com/essays/generalai/supervised_unsupervised_machine_learning.htm)
[机器学习PartII：监督学习和无监督学习 - Bati - 博客园 ](http://www.cnblogs.com/ysjxw/articles/1149004.html)


上次我们讨论了基于结果的两类学习。这篇文章我们将关注一些其他方面的学习：监督还是无监督。当训练用例被标记了正确结果的时候，监督学习方式为怎样改进学习给出一个反馈。这类似于教官教导某个Agent，它的行为是否正确。对无监督学习来说这个目标很难实现，因为缺乏事先确定的分类。

·监督学习

监督学习是最常见的分类问题，因为目标往往是让计算机去学习我们已经创建好的分类系统。数字识别再一次成为分类学习的常见样本。更一般地说，对于那些有用的分类系统，和容易判断的分类系统，分类学习都适用。在某些情况下，如果Agent能自行计算分类的话，它（Agent）可能不需要事先给出分类。这将在后面成为无监督学习上下文分类的一个例子。

监督学习是训练神经网络和决策树的最常见技术。这两种技术（神经网络和决策树）高度依赖于事先确定的分类系统给出的信息。对于神经网络来说，分类系统用于判断网络的错误，然后调整网络适应它；对于决策树，分类系统用来判断哪些属性提供了最多的信息，如此一来可以用它解决分类系统的问题。我们将会看到这两者（神经网络和决策树）更多的细节，但在目前，它们用预先确定分类方法的形式来“监督”就足够了。

使用隐马尔科夫模型和贝斯网络的语音识别系统也依赖于某些监督的要素，那通常是为了调节系统的参数以便于最小化给定输入中的错误。

请注意这里提到的一个问题：在分类问题中，学习算法的目标是把给定输入中的错误最小化。这些输入通常被称作“训练集”（原文为training set，译者注），它们是Agent尝试学习的样本。但是，学习训练集表现良好并不一定是件好事。例如，如果我试图教你学习exclusive-or（及逻辑或，译者注），但仅仅给出由一个真和一个假构成的组合，而不把同时为真或为假的组合告诉你，那么根据你学到的规则，你可能对任何问题回答都为真。同样，对于机器学习算法，一个通常的问题是过适合（原文为over-fitting，译者注）数据，以及主要记忆训练集，而不是学习过多的一般分类技术。

你可以这样设想，并不是所有的训练集的输入都分类正确。如果使用的算法有足够强的记忆力，但这显然是“特例”，不适合一般的原则，因此会出现问题。这一点也可能导致过适合。不但要在学习复杂函数时足够强大，而且能产生可概括的结论，寻找这样的算法的确是一个挑战。

·非监督学习

非监督学习看起来非常困难：目标是我们不告诉计算机怎么做，而是让它（计算机）自己去学习怎样做一些事情。非监督学习一般有两种思路。第一种思路是在指导Agent时不为其指定明确的分类，而是在成功时采用某种形式的激励制度。需要注意的是，这类训练通常会置于决策问题的框架里，因为它的目标不是产生一个分类系统，而是做出最大回报的决定。这种思路很好的概括了现实世界，Agent可以对那些正确的行为做出激励，并对其他的行为进行处罚。

强化学习的一些形式常常可以被用于非监督学习，由于没有必然的途径学习影响世界的那些行为的全部信息，因此Agent把它的行为建立在前一次奖惩的基础上。在某种意义上，所有的这些信息都是不必要的，因为通过学习激励函数，Agent不需要任何处理就可以清楚地知道要做什么，因为它（Agent）知道自己采取的每个动作确切的预期收益。对于防止为了计算每一种可能性而进行的大量计算，以及为此消耗的大量时间（即使所有世界状态的变迁概率都已知），这样的做法是非常有益的。另一方面，在尝试出错上，这也是一种非常耗费时间的学习。

不过这一类学习可能会非常强大，因为它假定没有事先分类的样本。在某些情况下，例如，我们的分类方法可能并非最佳选择。在这方面一个突出的例子是Backgammon（西洋双陆棋）游戏，有一系列计算机程序（例如neuro-gammon和TD-gammon）通过非监督学习自己一遍又一遍的玩这个游戏，变得比最强的人类棋手还要出色。这些程序发现的一些原则甚至令双陆棋专家都感到惊讶，并且它们比那些使用预分类样本训练的双陆棋程序工作得更出色。

一种次要的非监督学习类型称之为聚合（原文为clustering，译者注）。这类学习类型的目标不是让效用函数最大化，而是找到训练数据中的近似点。聚合常常能发现那些与假设匹配的相当好的直观分类。例如，基于人口统计的聚合个体可能会在一个群体中形成一个富有的聚合，以及其他的贫穷的聚合。

·总结

非监督学习已经获得了巨大的成功，例如西洋双陆棋程序world-champion calibre以及自动驾驶技术。当有一种为行为赋予权值的简单方法时，它可以成为一项强大的技术。当有足够的数据构成聚类（尽管有时这非常困难），聚合可能会非常有用，特别是一个聚类中关于成员的附加数据由于这些附加的数据可以用于产生更多的结果。

如果有恰当的分类系统（例如疾病处理程序，它一般会在实施自动诊断之后直接决定设计），分类学习也会非常强大，或者当分类是一件非常简单的事情，此时我们非常乐于让计算机为我们进行识别。如果通过算法作出的决定需要输入别的地方，这时分类学习是必要的。否则，对于需要输入的一方来说，计算它的含义将会非常困难。

这两种技术都非常有价值，你需要根据当时的情况决定需要选用哪一种技术——什么类型的问题被解决，解决它需要支出多少时间（通常来说,监督学习和聚合要比强化学习技术更快）,以及是否监督学习更有可能（完成）。


# 机器学习中的有监督学习，无监督学习，半监督学习

[机器学习中的有监督学习，无监督学习，半监督学习 - 小硒---代码无疆 - CSDN博客 ](http://blog.csdn.net/u011067360/article/details/24735415?utm_source=tuicool&utm_medium=referral)