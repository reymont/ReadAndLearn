Django Celery RabbitMQ构建异步消息队列 - 简书 https://www.jianshu.com/p/4e5c534f14e4

1. 建立消息队列
最常用的消息队列就是rabbitmq与redis，这里以rabbitmq为例

首先是安装rabbitmq
linux下安装
sudo apt-get install rabbitmq-server
mac下安装
brew install rabbitmq
启动rabbitmq
进入到 /usr/local/Cellar/rabbitmq目录下，执行

sbin/rabbitmq-server
mac用户也可以执行

brew services start rabbitmq 
终止rabbitmq
同样进入rabbitmq目录，执行

rabbitmqctl stop
2. 安装django-celery
最好建立Django虚拟目录

pip install celery
pip install django-celery
然后更新requirements.txt文件

pip freeze > requirements.txt
3. 配置settings.py
方式一
在Django工程的settings.py文件中加入如下配置代码：

import djcelery
djcelery.setup_loader()
BROKER_URL= 'amqp://guest@localhost//'
CELERY_RESULT_BACKEND = 'amqp://guest@localhost//'
其中，当djcelery.setup_loader()运行时，Celery便会去查看INSTALLD_APPS下包含的所有app目录中的tasks.py文件，找到标记为task的方法，将它们注册为celery task。

BROKER_URL和CELERY_RESULT_BACKEND分别指代你的Broker的代理地址以及Backend（result store）数据存储地址。在Django中如果没有设置backend，会使用其默认的后台数据库用来存储数据。

注意，此处backend的设置是通过关键字CELERY_RESULT_BACKEND来配置，与一般的.py文件中实现celery的backend设置方式有所不同。一般的.py中是直接通过设置backend关键字来配置，如下所示：

app = Celery('tasks', backend='amqp://guest@localhost//', broker='amqp://guest@localhost//')
一般py文件中的配置方式与方式三有点相似

方式二
我么已经知道Celery需要broker，使用django自身便可以充当broker(但在部署时, 我们最好使用更稳定和高效的broker, 例如redis)

    import djcelery
    djcelery.setup_loader()
    BROKER_URL = 'django://'
    ...
    INSTALLED_APPS = (
       ...
       'djcelery',
       'kombu.transport.django',
       ...
    )
第一二项是必须的, 第三项则告诉Celery使用Django项目作为broker.
在INSTALLED_APPS中添加的djcelery是必须的，
kombu.transport.django则是基于Django的broker

方式三
与常规py文件相似
settings.py

CELERY_TIMEZONE = 'Asia/Shanghai'
CELERY_BROKER = 'amqp://guest@localhost//'
celery.py

from __future__ import absolute_import

import os

from celery import Celery
from django.conf import settings

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'cos.settings')
app.autodiscover_tasks(lambda: settings.INSTALLED_APPS)  
 
@app.task(bind=True)  
def debug_task(self):  
    print('Request: {0!r}'.format(self.request))  
配置说明
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'django_celery.settings')
设置这个环境变量是为了让 celery 命令能找到 Django 项目，这条语句必须出现在 Celery 实例创建之前。

app = Celery('django_celery')

这个 app 就是 Celery 实例。可以有很多 Celery 实例，但是当使用 Django 时，似乎没有必要。

app.config_from_object('django.conf:settings')

可以将 settings 对象作为参数传入，但是更好的方式是使用字符串，因为当使用 Windows 系统或者 execv 时 celery worker 不需要序列化 settings 对象。

app.autodiscover_tasks(lambda: settings.INSTALLED_APPS)

为了重用 Django APP，通常是在单独的 tasks.py 模块中定义所有任务。Celery 会自动发现这些模块，加上这一句后，Celery 会自动发现 Django APP 中定义的任务，前提是遵循如下 tasks.py 约定：

- app1/    
- tasks.py    
- models.py
- app2/   
- tasks.py    
- models.py
当然，也可以不用这样循规蹈矩，随便定义task，然后在app的include里面添加注册，例如：

from __future__ import absolute_import

import os

from celery import Celery
from django.conf import settings

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'cos.settings')


app = Celery('order', broker=settings.CELERY_BROKER, include=['cos.task.pay_queue_task'])
app.config_from_object('django.conf:settings')
就是精简写法

关于broker：
BROKER_URL = 'django://localhost:8000//'
这里使用了django自带的broker来作为celery broker

4.创建Celery所需的数据表
Django1.7以下版本：
python manage.py syncdb
Django1.7以上版本
python manage.py migrate
python manage.py makemigrations
5.建立tasks.py
方式一
@task
def pay_query_queue(erp_data):
    pass
方式二
class TaskCelery(Task):
    @task
    def add(a, b):
        return a + b
方式三
@shared_task  
def add(x, y):  
    return x + y 
4.方式四

@app.task 
def add(x, y):  
    return x + y 
6.生产任务
方式一
用build_job.delay的方式来创建任务，并送入消息队列
def func():
        try:
            pay_query_queue.delay(erp_data)
        except Exception as e:
            pass
方式二
def func():
        try:
            pay_query_queue.apply_async((erp_data))
        except Exception as e:
            pass
apply_async允许你指定一些执行选项，如何时开始执行任务，任务应该被发送给哪个队列等等。

add.apply_async((2, 2), queue='lopri', countdown=10)
上面的举例中，任务将会被发送给lopri队列，任务最早将会在消息发送10s之后执行。

7. 启动worker
先启动服务器
python manage.py runserver
再启动worker
python manage.py celery worker -c 4 --loglevel=info
celery -A app_name worker -l info
8. 查看rabbitmq消息
如果rabbitmq正确安装启动，则可以通过浏览器进入后台查看进程

http://localhost:15672/

账号密码默认都是guest

9.查看celery队列
首先安装flower模块

pip install flower
然后启动flower，默认端口5555

python manage.py celery flower
最后浏览器输入：

http://localhost:5555

作者：Sunnky
链接：https://www.jianshu.com/p/4e5c534f14e4
来源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。