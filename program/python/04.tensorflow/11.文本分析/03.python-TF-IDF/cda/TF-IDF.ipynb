{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['加势大周 日本 广告 可口可乐', '伊拉克 原油 科威特 波斯湾 沙特阿拉伯', '原油 科威特 波斯湾 沙特阿拉伯', '新世航一号 渔船 喋血案 游闻道 吕政道', '新世航 渔船 喋血案 刘宪助']\n",
      "  (0, 4)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 15)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 15)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 14)\t1\n",
      "  (3, 6)\t1\n",
      "  (3, 13)\t1\n",
      "  (3, 9)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 8)\t1\n",
      "  (4, 6)\t1\n",
      "  (4, 13)\t1\n",
      "[[0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1]\n",
      " [0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0]\n",
      " [0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0]]\n",
      "['伊拉克', '刘宪助', '加势大周', '原油', '可口可乐', '吕政道', '喋血案', '广告', '新世航', '新世航一号', '日本', '沙特阿拉伯', '波斯湾', '渔船', '游闻道', '科威特']\n",
      "[[1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "query = ['波斯湾 伊拉克 原油']\n",
    "\n",
    "'''\n",
    "corpus = [ 'This is the first document.',\n",
    "           'This is the second second document.',\n",
    "           'And the third one.',\n",
    "           'Is this the first document?'\n",
    "         ]\n",
    "\n",
    "\n",
    "corpus = [ '加势大周 日本 广告 可口可乐',\n",
    "           '伊拉克 原油 科威特 波斯湾 沙特阿拉伯',\n",
    "           '原油 科威特 波斯湾 沙特阿拉伯',\n",
    "           '新世航一号 渔船 喋血案 游闻道 吕政道',\n",
    "           '新世航 渔船 喋血案 刘宪助'\n",
    "         ]\n",
    "'''\n",
    "\n",
    "corpus = []\n",
    "\n",
    "with open('document.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        corpus.append(line.strip('\\n'))\n",
    "\n",
    "\n",
    "print(corpus)\n",
    "\n",
    "#min_df=Specifies the minimum number of different documents a term must appear in to be included in the vocabulary\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "\n",
    "#得到TF Matrix\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print (X)\n",
    "print (X.toarray())\n",
    "\n",
    "#词的对应索引值\n",
    "feature_name = vectorizer.get_feature_names()\n",
    "print (feature_name)\n",
    "\n",
    "#Transform Query to KW Vector\n",
    "Q = vectorizer.transform(query)\n",
    "print(Q.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10)\t0.5\n",
      "  (0, 7)\t0.5\n",
      "  (0, 4)\t0.5\n",
      "  (0, 2)\t0.5\n",
      "  (1, 15)\t0.4250013751329181\n",
      "  (1, 12)\t0.4250013751329181\n",
      "  (1, 11)\t0.4250013751329181\n",
      "  (1, 3)\t0.4250013751329181\n",
      "  (1, 0)\t0.52677824987419\n",
      "  (2, 15)\t0.5\n",
      "  (2, 12)\t0.5\n",
      "  (2, 11)\t0.5\n",
      "  (2, 3)\t0.5\n",
      "  (3, 14)\t0.4821401170833009\n",
      "  (3, 13)\t0.3889876106617681\n",
      "  (3, 9)\t0.4821401170833009\n",
      "  (3, 6)\t0.3889876106617681\n",
      "  (3, 5)\t0.4821401170833009\n",
      "  (4, 13)\t0.44400207886377085\n",
      "  (4, 8)\t0.5503291323968319\n",
      "  (4, 6)\t0.44400207886377085\n",
      "  (4, 1)\t0.5503291323968319\n",
      "[[0.         0.         0.5        0.         0.5        0.\n",
      "  0.         0.5        0.         0.         0.5        0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.52677825 0.         0.         0.42500138 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.42500138\n",
      "  0.42500138 0.         0.         0.42500138]\n",
      " [0.         0.         0.         0.5        0.         0.\n",
      "  0.         0.         0.         0.         0.         0.5\n",
      "  0.5        0.         0.         0.5       ]\n",
      " [0.         0.         0.         0.         0.         0.48214012\n",
      "  0.38898761 0.         0.         0.48214012 0.         0.\n",
      "  0.         0.38898761 0.48214012 0.        ]\n",
      " [0.         0.55032913 0.         0.         0.         0.\n",
      "  0.44400208 0.         0.55032913 0.         0.         0.\n",
      "  0.         0.44400208 0.         0.        ]]\n",
      "[[0.659118   0.         0.         0.53177225 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.53177225 0.         0.         0.        ]]\n",
      "0.0\n",
      "0.7992169056459312\n",
      "0.5317722537280788\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "\n",
    "transformer = TfidfTransformer(smooth_idf=True)\n",
    "\n",
    "tfidf = transformer.fit_transform(X) \n",
    "print (tfidf)\n",
    "print (tfidf.toarray())\n",
    "\n",
    "print(transformer.transform(Q).toarray())\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    print(sum(transformer.transform(Q).toarray()[0] * tfidf.toarray()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79259392]]\n",
      "[[0.33333333]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.63245553]]\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "d1 = [0.602, 0.602, 0.602, 0.301, 0, 0, 0, 0, 0, 0, 0]\n",
    "d2 = [0,0.301,0,0.301,0.602,0,0,0,0,0,0]\n",
    "d3 = [0,0,0,0,0,0.602,0.301,0.301,0.602,0,0]\n",
    "d4 = [0,0,0,0,0,0,0.602,0.602,0,0.602,0.602]\n",
    "q1 = [0.602, 0.301, 0, 0.301, 0, 0, 0, 0, 0, 0, 0]\n",
    "q2 = [0,0,0,0,0,0.602,0,0,0,0,0]\n",
    "\n",
    "print (cosine_similarity(np.mat(d1),np.mat(q1)))\n",
    "print (cosine_similarity(np.mat(d2),np.mat(q1)))\n",
    "print (cosine_similarity(np.mat(d3),np.mat(q1)))\n",
    "print (cosine_similarity(np.mat(d4),np.mat(q1)))\n",
    "\n",
    "print (cosine_similarity(np.mat(d1),np.mat(q2)))\n",
    "print (cosine_similarity(np.mat(d2),np.mat(q2)))\n",
    "print (cosine_similarity(np.mat(d3),np.mat(q2)))\n",
    "print (cosine_similarity(np.mat(d4),np.mat(q2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t0.5\n",
      "  (0, 10)\t0.5\n",
      "  (0, 7)\t0.5\n",
      "  (0, 4)\t0.5\n",
      "  (1, 0)\t0.52677824987419\n",
      "  (1, 3)\t0.4250013751329181\n",
      "  (1, 15)\t0.4250013751329181\n",
      "  (1, 12)\t0.4250013751329181\n",
      "  (1, 11)\t0.4250013751329181\n",
      "  (2, 3)\t0.5\n",
      "  (2, 15)\t0.5\n",
      "  (2, 12)\t0.5\n",
      "  (2, 11)\t0.5\n",
      "  (3, 9)\t0.4821401170833009\n",
      "  (3, 13)\t0.3889876106617681\n",
      "  (3, 6)\t0.3889876106617681\n",
      "  (3, 14)\t0.4821401170833009\n",
      "  (3, 5)\t0.4821401170833009\n",
      "  (4, 13)\t0.44400207886377085\n",
      "  (4, 6)\t0.44400207886377085\n",
      "  (4, 8)\t0.5503291323968319\n",
      "  (4, 1)\t0.5503291323968319\n",
      "[[0.         0.         0.5        0.         0.5        0.\n",
      "  0.         0.5        0.         0.         0.5        0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.52677825 0.         0.         0.42500138 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.42500138\n",
      "  0.42500138 0.         0.         0.42500138]\n",
      " [0.         0.         0.         0.5        0.         0.\n",
      "  0.         0.         0.         0.         0.         0.5\n",
      "  0.5        0.         0.         0.5       ]\n",
      " [0.         0.         0.         0.         0.         0.48214012\n",
      "  0.38898761 0.         0.         0.48214012 0.         0.\n",
      "  0.         0.38898761 0.48214012 0.        ]\n",
      " [0.         0.55032913 0.         0.         0.         0.\n",
      "  0.44400208 0.         0.55032913 0.         0.         0.\n",
      "  0.         0.44400208 0.         0.        ]]\n",
      "[[0.659118   0.         0.         0.53177225 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.53177225 0.         0.         0.        ]]\n",
      "[0.659118   0.         0.         0.53177225 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.53177225 0.         0.         0.        ]\n",
      "[[0.]]\n",
      "[[0.79921691]]\n",
      "[[0.53177225]]\n",
      "[[0.]]\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "vectorizer2 = TfidfVectorizer(smooth_idf=True)\n",
    "\n",
    "tfidf2 = vectorizer2.fit_transform(corpus)\n",
    "print (tfidf2)\n",
    "print (tfidf2.toarray())\n",
    "print (vectorizer2.transform(query).toarray())\n",
    "\n",
    "# 计算查询与文件间的相似度\n",
    "for i in range(len(corpus)):\n",
    "    print(cosine_similarity(vectorizer2.transform(query).toarray(),np.mat(tfidf2.toarray()[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
